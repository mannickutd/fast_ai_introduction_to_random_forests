# fast_ai_introduction_to_random_forests
Fast.ai Introduction to Random Forests


## Notes on the lecture

Curse of dimensionality
“Curse of dimensionality” → theoreticians don’t like many dimensions (aka columns), but in practical use the more information the better because you don’t know what might be.

No free lunch theorem → In theory, no one type of model will work well for any kind of data set, which true for random data sets

Jeremy’s “free lunch theorem” → in practice, random forest is the best model for most data b/c most data is not random. A random-forest decision tree works for almost every structured-data problem.

Q: if we have too many dimensions/fields won’t we run into co-linearity problems?
Random forests have almost no co-linearity problems
